% Compile with the official ACL style files:
%   acl.sty, acl_natbib.bst

\documentclass[11pt]{article}

\usepackage[hyperref]{acl}
\usepackage{times}
\usepackage{latexsym}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{natbib}

\title{Shout: Privacy-Preserving Browser-Based ASR \& Reconstruction Speech Transcription for North-American Low-Resource Languages}

% Replace with your author block / affiliation as needed
\author{Imad Benahmed, Jean-Christophe Clouâtre, Cassandre Hamel, Vennila Sooben\\
Affiliation\\
\texttt{imad.benahmed@umontreal.ca, jean-christophe.clouatre@umontreal.ca}\\
\texttt{cassandre.hamel.1@umontreal.ca, vennila.sooben@umontreal.ca}}

\begin{document}
\maketitle

\begin{abstract}
In the current state of automatic speech recognition there remains a lack of focus on North-American low-resource languages, specifically located in the territory known as Canada. This is a multi-faceted problem stemming from data scarcity, privacy concerns for the populations affected, and current models not representing polysynthetic languages very well. Furthermore existing transcription tools either require cloud processing (raising privacy and data sovereignty concerns),or lack support for morphologically complex languages entirely. We will create a tool based on one base quantized whisper model with language-specific LoRA adapters and a reconstruction module that will be triggered through uncertainty deployed entirely in the browser via WASM for utmost privacy and control over usage and data. \citep{radford2023whisper,song24_interspeech,whispercpp} By deploying entirely on-device, we ensure that speech data never leaves the user’s browser, respecting Indigenous data sovereignty principles. \citep{fnigc_ocap} We will measure success using WER/CER metrics on a variety of proxy languages as well as latency and memory profiling with ablations on the single pass ASR vs. reconstruction on languages that set off uncertainty threshold. We will contribute a browser deployed ASR for an indigenous language, a systematic evaluation of reconstruction for polysynthetic languages and a release of the fine-tuned adapters. We target North American Indigenous polysynthetic languages, prioritizing Plains Cree and Inuktitut pending data access agreements with NRC and university partners. \citep{nrc_ilt_factsheet,itwewina_about} If primary data is unavailable, we evaluate on typologically similar languages (Greenlandic, Nahuatl) with publicly available corpora to demonstrate methodology transferability. \citep{giellalt_langkal,openslr92}
\end{abstract}

\section{Introduction}
\paragraph{Context.}
Indigenous languages across North America face critical endangerment, with approximately 237,420 Indigenous people in Canada that could speak an Indigenous language well enough to conduct a conversation in 2021, down by 4.3%, from 2016. use satscan stats, there are data sovereignty principles so cloud is a nono. \citep{statcan2021aboriginal,fnigc_ocap}  The issue keeps getting worse with technological marginalization. Indeed, modern automatic speech recognition (ASR) systems demonstrate poor performance on Indigenous languages.This disparity stems from several factors including severe data scarcity, morphological complexity of polysynthetic languages and the fundamental mismatch between training data distributions of foundations models like Whisper (Ratford 2024.)  . \citep{radford2023whisper} and the linguistic structure of Indigenous languages. No existing browser-based ASR system supports North American Indigenous languages. While browser-based ASR has been successful for high-resource languages using WebAssembly deployment (Song et Al. 2024), \citep{song24_interspeech} this approach has not been extended to low-resource or morphologically complex languages. In fact, polysynthetic languages (where single words encode entire sentences in languages like English) present several challenges. This is because languages like Mohawk (Kanien'kéha), Cree (nēhiyawēwin), and Innu-aimun whose morphological complexity leads to exponential vocabulary growth and ambiguous word boundaries that confound standard ASR architectures trained primarily on isolating languages.

\paragraph{Objectives.}
We propose Shout: an in browser ASR \& Reconstruction tool for Low-Resource languages. Many current Speech To Text (STT) models fail at boundaries of words in polysynthetic languages due to their complex morphological structure, where single words may encode entire predicate-argument structures. What more, many communities linked to these low-resource languages may not have access to a large amount of compute, or a stable internet connection hence our focus on ending up with a small in-browser model for STT. There is also evidence to suggest that for polysynthetic languages like Mohawk, that using morphological reconstruction post-ASR output allows for increased performance. Specifically, the research objectives are to: (O1) Develop a lightweight ASR system with LORA adapters for efficient multilingual support, (O2) Implement uncertainty-triggered morphological reconstruction, and (O3) Deploy the complete system in-browser via WebAssembly ensuring data privacy and accessibility without server dependencies. Our language selection follows a principled prioritization based on the following criteria: (1) Polysynthetic Structure, (2) Availability of existing linguistic tools (morphological analyzers, lexicons) and (3) alignment with Canadian Indigenous language revitalization priorities. We are currently prioritizing Plains Cree due to the availability of the itwêwina morphological analyzer (ALTLab, University of Alberta) [..] \citep{itwewina_about} and published ASR baselines Gupta \& Boulianne, 2020 [..]. \citep{gupta2020inuktitut,gupta2020cree} Our secondary priority is Inuktitut, which has NRC developed tools. \citep{nrc_ilt_factsheet} Following from there we will prioritize Mohawk, and Innu. The final language selection will be contingent on data access agreements and morphological tool availability with evaluation on proxy polysynthetic languages as a fallback.

\section{Related Work}
ASR for North American Indigenous languages faces unique challenges stemming from data scarcity (StatsCan) \citep{statcan2021aboriginal} and morphological complexity due to their polysynthetic nature. Gupta \& Boulianne (2020a, 2020b) \citep{gupta2020inuktitut,gupta2020cree} established baselines for Iniktitit and East Cree,  reporting 74.3\% word error rate (WER) for speaker-independent Inuktitut and 60\%+ out-of-vocabulary rates even with a 1.3-million-word lexicon. Their work found that syllable-based units with boundary markers outperform word-based tokenization for polysynthetic languages. However, these systems require server infrastructure and do not address privacy or deployment constraints relevant to Indigenous communities. Large-scale foundation models like Whisper (Radford et al. 2023) \citep{radford2023whisper} offer multilingual capabilities, but they underperform on underrepresented languages.  Le Ferrand et al. (2024) \citep{le_ferrand_2024} confirm this, finding that modern ASR architectures show disproportionately high WER on polysynthetic languages while character error rates remain acceptable. This WER-CER divergence suggests that acoustic modeling succeeds but word-level composition fails, motivating our approach of post-ASR reconstruction. LoRA allows for efficient language-specific adaptation without catastrophic forgetting as shown by Song et al. (2024). \citep{song24_interspeech} It was demonstrated that LoRA adapters of rank-32 with \textasciitilde 13M parameters per language achieve 18.5\% relative WER improvement over multilingual finetuning with no catastrophic forgetting when adding new languages. However it is important to note, as of now LoRA-Whisper has not been evaluated for polysynthetic languages. Reconstruction approaches can recover accuracy lost during ASR decoding. Diwan \& Jyothi (2021) \citep{diwan21b_interspeech} introduced Reduce and Reconstruct, using FST-based post-processing to achieve 7\% WER reduction on two low-resource languages. Finally, Browser-Based ASR is technically feasible as shown by the existence of Whisper.cpp \citep{whispercpp} but the effects of quantization on low-resource polysynthetic languages is underexplored. \citep{andreyev2025quantization} Our work addresses these gaps by combining LoRA adaptation, reconstruction, and browser deployment for Canadian Indigenous polysynthetic languages.

\section{Task and Dataset}
Our task is to do an automatic speech recognition with morphological reconstruction for polysynthetic Indigenous languages. Given an audio file in a target language, the system must: (1) transcribe the speech to text using adapted Whisper models, (2) detect segments with low confidence scores indicating potential morphological errors and (3) apply reconstruction to correct detected mistakes. We evaluate both transcription accuracy (WER, CER) and morphological correctness (morpheme boundary F1-score). Our primary dataset is the Maskwacîs Speech Database, a community developed corpus specifically designed for ASR research containing over 22k unique words and sentences with 1 to 5 recordings each. \citep{poulin2023speechdb} We will leverage the itwêwina morphological  analyzer (cite itwewina ici TODO) developed by ALTLab (University of Alberta). \citep{itwewina_about} However if access to Maskwacîs cannot be secured within our project timeline, we implemented a 2-tiered fallback strategy. First, is to request access to any available Indigenous language speech data through Université de Montréal linguistics department, which has documented work on Canadian Indigenous languages. Our second option is to use proxy Polysynthetic Language, If neither Maskwacîs nor UdeM  access is secured, we will evaluate on  Greenlandic (Kalaallisut), a polysynthetic Eskimo-Aleut language typologically similar to Inuktitut, using Mozilla CommonVoice Greenlandic dataset, \citep{ardila2020commonvoice} Martha morphological analyzer (cite github) which provides morphological parsing for Greenlandic. \citep{giellalt_langkal}

\section{Methods}
We will develop a fully in-browser ASR pipeline with three components: (O1) on-device transcription using a quantized Whisper model with a pretrained, language-specific LoRA adapter loaded at runtime, \citep{radford2023whisper,song24_interspeech,andreyev2025quantization} (O2) a confidence-gated reconstruction stage that activates when decoder confidence falls below a tuned threshold (selected via ablation on a dev set), and (O3) a client-side deployment using WebAssembly to keep audio on-device. \citep{whispercpp} For reconstruction, we will compare: (1) lexicon-constrained edit-distance correction, (2) FST/morphological-analyzer validation and candidate selection, (3) lightweight character-level neural post-correction, and (4) a hybrid of (1)+(2) with an explicit failure flag. \citep{diwan21b_interspeech}

\section{Baselines and Evaluation}
We will evaluate our approach against several baselines to isolate the contribution of each component. Baselines: (B1) Whisper (no adaptation) - measures the base model performance. (B2) Whisper \& LoRA, isolates the benefit of language-specific adaptation. (B3) Whisper \& full tine-tuning, measures LoRA vs. full training trade-off. (B4) Whisper \& LoRA \& reconstruction, which is our proposed system), (B5) Whisper \& full fine tuning \& reconstruction, upper bound performance. Metrics: - Accuracy: Word Error Rate (WER), Character Error Rate (CER), F1-Score (for the morpheme boundary detection that will evaluate the model’s ability to recover linguistically meaningful morphological structure). - Efficiency: Real-Time Factor (RTF), peak memory usage, model size (MB). - Latency: End-to-end transcription time that measures the total time from audio input to final reconstructed output, capturing the user-perceived responsiveness of the system., reconstruction overhead. All experiments will be run in-browser using Chrome/Firefox to ensure realistic performance evaluation.

\section{Challenges}
Several challenges can be highlighted in regards to this project. A challenge stemming from our architectural choices would be browser performance constraints, namely memory and latency. Indigenous language speech data is scarce and often governed by community data sovereignty agreements. \citep{fnigc_ocap} We address this through: (1) formal requests to NRC, ALTLab, and community partners at the University of Montreal, \citep{nrc_ilt_factsheet} (2) Fallback plan for evaluation on publicly available polysynthetic language data using Nahuatl or Greenlandic to ensure methodological contributions are demonstrable in theory. \citep{openslr92,giellalt_langkal} For the full fine-tune evaluation and ablation, we would need access to large amounts of compute or be constrained to smaller benchmarks and ablations.

\bibliographystyle{acl_natbib}
\bibliography{custom}

\end{document}
